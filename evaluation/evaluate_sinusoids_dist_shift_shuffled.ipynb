{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import load_model\n",
    "from argparse import Namespace\n",
    "\n",
    "from dataset.dataset import SetKnowledgeTrendingSinusoidsDistShift\n",
    "from dataset.utils import get_dataloader\n",
    "from evaluation.utils import get_summary_df\n",
    "from models.loss import NLL\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"science\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Dark2\")\n",
    "plt.rcParams[\"text.latex.preamble\"] = (\n",
    "    \"\\\\usepackage{lmodern} \\\\usepackage{times} \\\\usepackage{amssymb}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "save_dirs = {\n",
    "    \"NP\": \"../saves/INPs_sinusoids/np_dist_shift_1\",\n",
    "    \"INP\": \"../saves/INPs_sinusoids/inp_b_dist_shift_1\",\n",
    "    # Update the path below to the contrastive run you want to compare.\n",
    "    \"INP (contrastive)\": \"../saves/INPs_sinusoids/inp_b_dist_shift_contrastive_1\",\n",
    "}\n",
    "\n",
    "models = list(save_dirs.keys())\n",
    "model_dict = {}\n",
    "config_dict = {}\n",
    "\n",
    "for model_name, save_dir in save_dirs.items():\n",
    "    model_dict[model_name], config_dict[model_name] = load_model(\n",
    "        save_dir, load_it=\"best\"\n",
    "    )\n",
    "    model_dict[model_name].eval()\n",
    "\n",
    "model_names = list(model_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the dataloaders\n",
    "config = Namespace(\n",
    "    min_num_context=0,\n",
    "    max_num_context=100,\n",
    "    num_targets=100,\n",
    "    noise=0.2,\n",
    "    batch_size=25,\n",
    "    x_sampler=\"uniform\",\n",
    "    test_num_z_samples=32,\n",
    "    dataset=\"set-trending-sinusoids-dist-shift\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "test_dataset = SetKnowledgeTrendingSinusoidsDistShift(\n",
    "    root=\"../data/trending-sinusoids-dist-shift\", split=\"test\", knowledge_type=\"b\"\n",
    ")\n",
    "test_data_loader = get_dataloader(test_dataset, config)\n",
    "\n",
    "train_dataset = SetKnowledgeTrendingSinusoidsDistShift(\n",
    "    root=\"../data/trending-sinusoids-dist-shift\", split=\"train\", knowledge_type=\"b\"\n",
    ")\n",
    "train_data_loader = get_dataloader(train_dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sampler(num_targets, num_context):\n",
    "    return np.random.choice(list(range(num_targets)), num_context, replace=False)\n",
    "\n",
    "\n",
    "def _randperm_no_fixed(bs, device):\n",
    "    perm = torch.randperm(bs, device=device)\n",
    "    fixed = perm == torch.arange(bs, device=device)\n",
    "    if fixed.any():\n",
    "        perm[fixed] = (perm[fixed] + 1) % bs\n",
    "    return perm\n",
    "\n",
    "\n",
    "def _shuffle_knowledge(knowledge, perm):\n",
    "    if isinstance(knowledge, torch.Tensor):\n",
    "        return knowledge[perm]\n",
    "    k_list = list(knowledge)\n",
    "    perm_cpu = perm.detach().cpu().tolist()\n",
    "    return [k_list[i] for i in perm_cpu]\n",
    "\n",
    "\n",
    "def make_fully_mismatched_knowledge(knowledge, device):\n",
    "    if knowledge is None:\n",
    "        return None\n",
    "    bs = len(knowledge) if not isinstance(knowledge, torch.Tensor) else knowledge.shape[0]\n",
    "    if bs < 2:\n",
    "        return knowledge\n",
    "    perm = _randperm_no_fixed(bs, device=device)\n",
    "    return _shuffle_knowledge(knowledge, perm)\n",
    "\n",
    "\n",
    "def get_summary_df_shuffled(\n",
    "    model_dict,\n",
    "    config_dict,\n",
    "    data_loader,\n",
    "    eval_type_ls,\n",
    "    model_names,\n",
    "    sampler=uniform_sampler,\n",
    "):\n",
    "    loss = NLL(reduction=\"none\")\n",
    "\n",
    "    losses = {}\n",
    "    outputs_dict = {}\n",
    "\n",
    "    num_context_ls = [0, 1, 3, 5, 10, 15]\n",
    "    for model_name in model_names:\n",
    "        losses[model_name] = {}\n",
    "        outputs_dict[model_name] = {}\n",
    "        for eval_type in eval_type_ls:\n",
    "            losses[model_name][eval_type] = {}\n",
    "            outputs_dict[model_name][eval_type] = {}\n",
    "            for num_context in num_context_ls:\n",
    "                losses[model_name][eval_type][num_context] = []\n",
    "                outputs_dict[model_name][eval_type][num_context] = []\n",
    "\n",
    "    for model_name in model_names:\n",
    "        model, config = model_dict[model_name], config_dict[model_name]\n",
    "\n",
    "        for batch in data_loader:\n",
    "            (x_context, y_context), (x_target, y_target), knowledge, extras = batch\n",
    "            x_context = x_context.to(config.device)\n",
    "            y_context = y_context.to(config.device)\n",
    "            x_target = x_target.to(config.device)\n",
    "            y_target = y_target.to(config.device)\n",
    "\n",
    "            if isinstance(knowledge, torch.Tensor):\n",
    "                knowledge = knowledge.to(config.device)\n",
    "\n",
    "            shuffled_knowledge = make_fully_mismatched_knowledge(knowledge, config.device)\n",
    "\n",
    "            for num_context in num_context_ls:\n",
    "                for _ in range(3):\n",
    "                    sample_idx = sampler(x_target.shape[1], max(num_context_ls))\n",
    "                    x_context = x_target[:, sample_idx[:num_context], :]\n",
    "                    y_context = y_target[:, sample_idx[:num_context], :]\n",
    "\n",
    "                    for eval_type in eval_type_ls:\n",
    "                        with torch.no_grad():\n",
    "                            if eval_type == \"raw\":\n",
    "                                outputs = model(\n",
    "                                    x_context,\n",
    "                                    y_context,\n",
    "                                    x_target,\n",
    "                                    y_target=y_target,\n",
    "                                    knowledge=None,\n",
    "                                )\n",
    "                            elif config.use_knowledge and eval_type == \"shuffled\":\n",
    "                                outputs = model(\n",
    "                                    x_context,\n",
    "                                    y_context,\n",
    "                                    x_target,\n",
    "                                    y_target=y_target,\n",
    "                                    knowledge=shuffled_knowledge,\n",
    "                                )\n",
    "                            else:\n",
    "                                continue\n",
    "                            outputs = tuple(\n",
    "                                [o.cpu() if isinstance(o, torch.Tensor) else o for o in outputs]\n",
    "                            )\n",
    "                            loss_value, _, _ = loss.get_loss(\n",
    "                                outputs[0], outputs[1], outputs[2], outputs[3], y_target\n",
    "                            )\n",
    "                            losses[model_name][eval_type][num_context].append(loss_value)\n",
    "                            outputs_dict[model_name][eval_type][num_context].append(\n",
    "                                {\n",
    "                                    \"outputs\": outputs,\n",
    "                                    \"x_context\": x_context.cpu(),\n",
    "                                    \"y_context\": y_context.cpu(),\n",
    "                                    \"x_target\": x_target.cpu(),\n",
    "                                    \"y_target\": y_target.cpu(),\n",
    "                                    \"knowledge\": knowledge,\n",
    "                                    \"shuffled_knowledge\": shuffled_knowledge,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "    loss_summary = {}\n",
    "    for model_name in model_names:\n",
    "        loss_summary[model_name] = {}\n",
    "        for eval_type in eval_type_ls:\n",
    "            loss_summary[model_name][eval_type] = {}\n",
    "            for num_context in num_context_ls:\n",
    "                loss_summary[model_name][eval_type][num_context] = {}\n",
    "                loss_values = losses[model_name][eval_type][num_context]\n",
    "                if len(loss_values) == 0:\n",
    "                    loss_summary[model_name][eval_type][num_context][\"mean\"] = np.nan\n",
    "                    loss_summary[model_name][eval_type][num_context][\"std\"] = np.nan\n",
    "                else:\n",
    "                    loss_values = [lv[0] for lv in loss_values]\n",
    "                    loss_values = torch.stack(loss_values, dim=0)\n",
    "                    loss_summary[model_name][eval_type][num_context][\"median\"] = (\n",
    "                        torch.median(loss_values).item()\n",
    "                    )\n",
    "                    loss_summary[model_name][eval_type][num_context][\"mean\"] = (\n",
    "                        torch.mean(loss_values).item()\n",
    "                    )\n",
    "                    loss_summary[model_name][eval_type][num_context][\"std\"] = torch.std(\n",
    "                        loss_values\n",
    "                    ).item()\n",
    "\n",
    "    loss_summary_df = pd.DataFrame.from_dict(\n",
    "        {(i, j, k): loss_summary[i][j][k] for i in loss_summary for j in loss_summary[i] for k in loss_summary[i][j]},\n",
    "        orient=\"index\",\n",
    "    )\n",
    "    loss_summary_df[\"model_name\"] = [idx[0] for idx in loss_summary_df.index]\n",
    "    loss_summary_df[\"eval_type\"] = [idx[1] for idx in loss_summary_df.index]\n",
    "    loss_summary_df[\"num_context\"] = [idx[2] for idx in loss_summary_df.index]\n",
    "    loss_summary_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return loss_summary_df, losses, outputs_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_type_ls = [\"raw\", \"shuffled\"]\n",
    "\n",
    "train_summary_df, _, train_output_dict = get_summary_df_shuffled(\n",
    "    model_dict, config_dict, train_data_loader, eval_type_ls, model_names\n",
    ")\n",
    "test_summary_df, _, test_output_dict = get_summary_df_shuffled(\n",
    "    model_dict, config_dict, test_data_loader, eval_type_ls, model_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary_df[\"split\"] = \"train\"\n",
    "test_summary_df[\"split\"] = \"test\"\n",
    "\n",
    "plot_df = pd.concat([train_summary_df, test_summary_df])\n",
    "plot_df = plot_df[\n",
    "    ((plot_df.model_name == \"INP\") & (plot_df.eval_type == \"shuffled\"))\n",
    "    | ((plot_df.model_name == \"INP (contrastive)\") & (plot_df.eval_type == \"shuffled\"))\n",
    "    | ((plot_df.model_name == \"NP\") & (plot_df.eval_type == \"raw\"))\n",
    "]\n",
    "\n",
    "plot_df[\"mean\"] = -plot_df[\"mean\"]\n",
    "label_map = {\n",
    "    \"NP\": r\"NP: $\\mathcal{K} = \\varnothing$\",\n",
    "    \"INP\": r\"INP: shuffled $\\mathcal{K}$\",\n",
    "    \"INP (contrastive)\": r\"INP (contrastive): shuffled $\\mathcal{K}$\",\n",
    "}\n",
    "plot_df[\"model_label\"] = plot_df[\"model_name\"].map(label_map)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.6, 3.5))\n",
    "sns.lineplot(\n",
    "    plot_df,\n",
    "    x=\"num_context\",\n",
    "    y=\"mean\",\n",
    "    hue=\"model_label\",\n",
    "    style=\"split\",\n",
    "    palette=[\"C2\", \"C4\", \"C1\"],\n",
    "    markers=True,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Negative Log-likelihood\")\n",
    "ax.set_xlabel(\"Number of context datapoints\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"../figures/exp-2-shuffled.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NLL()\n",
    "\n",
    "\n",
    "def get_loss_bs(output_dict, model_name=\"INP\", eval_type=\"informed\", num_context=0):\n",
    "    bs_ls = []\n",
    "    this_loss_ls = []\n",
    "    for batch_idx in range(len(output_dict[model_name][eval_type][num_context])):\n",
    "        outputs = output_dict[model_name][eval_type][num_context][batch_idx][\"outputs\"]\n",
    "        y_target = output_dict[model_name][eval_type][num_context][batch_idx][\n",
    "            \"y_target\"\n",
    "        ]\n",
    "        knowledge = output_dict[model_name][eval_type][num_context][batch_idx][\n",
    "            \"knowledge\"\n",
    "        ].cpu()\n",
    "        bs = knowledge[:, 0, 3]\n",
    "\n",
    "        this_loss, _, _ = loss.get_loss(\n",
    "            outputs[0], outputs[1].cuda(), outputs[2], outputs[3], y_target.cuda()\n",
    "        )\n",
    "        this_loss = this_loss.cpu()\n",
    "        this_loss_ls.append(this_loss)\n",
    "        bs_ls.append(bs)\n",
    "\n",
    "    bs = torch.cat(bs_ls)\n",
    "    this_loss = torch.cat(this_loss_ls)\n",
    "\n",
    "    return this_loss, bs\n",
    "\n",
    "\n",
    "train_loss_informed, train_bs_informed = get_loss_bs(\n",
    "    train_output_dict, eval_type=\"informed\"\n",
    ")\n",
    "test_loss_informed, test_bs_informed = get_loss_bs(\n",
    "    test_output_dict, eval_type=\"informed\"\n",
    ")\n",
    "test_loss_raw, test_bs_raw = get_loss_bs(\n",
    "    test_output_dict, eval_type=\"raw\", model_name=\"NP\"\n",
    ")\n",
    "\n",
    "\n",
    "bins = np.linspace(-0.5, 6, 10)\n",
    "\n",
    "raw_df = pd.DataFrame({\"b\": test_bs_raw, \"loss\": torch.log(test_loss_raw)})\n",
    "raw_df[\"bin\"] = pd.cut(raw_df[\"b\"], bins=bins)\n",
    "raw_df[\"eval_type\"] = \"raw\"\n",
    "informed_df = pd.DataFrame(\n",
    "    {\"b\": test_bs_informed, \"loss\": torch.log(test_loss_informed)}\n",
    ")\n",
    "informed_df[\"bin\"] = pd.cut(raw_df[\"b\"], bins=bins)\n",
    "informed_df[\"eval_type\"] = \"informed\"\n",
    "all_df = pd.concat([raw_df, informed_df]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(3, 3.5), sharex=True, height_ratios=[2, 1])\n",
    "\n",
    "sns.regplot(\n",
    "    data=raw_df,\n",
    "    label=r\"NP: $\\mathcal{K} = \\varnothing$\",\n",
    "    ax=axs[0],\n",
    "    x_ci=\"sd\",\n",
    "    x=\"b\",\n",
    "    y=\"loss\",\n",
    "    x_bins=bins,\n",
    "    fit_reg=False,\n",
    "    color=\"C2\",\n",
    ")\n",
    "sns.regplot(\n",
    "    data=informed_df,\n",
    "    label=r\"INP: $\\mathcal{K} \\neq \\varnothing$\",\n",
    "    ax=axs[0],\n",
    "    x_ci=\"sd\",\n",
    "    x=\"b\",\n",
    "    y=\"loss\",\n",
    "    x_bins=bins,\n",
    "    fit_reg=False,\n",
    "    color=\"C4\",\n",
    ")\n",
    "\n",
    "\n",
    "axs[1].hist(\n",
    "    train_bs_informed, color=\"grey\", alpha=0.8, bins=bins, density=True, align=\"left\"\n",
    ")\n",
    "axs[0].legend()\n",
    "axs[0].legend(\n",
    "    handletextpad=0.05,\n",
    "    loc=\"lower right\",\n",
    "    facecolor=\"white\",\n",
    "    framealpha=0.8,\n",
    "    frameon=True,\n",
    ")\n",
    "axs[0].set_ylabel(\"test log(loss)\")\n",
    "axs[1].set_ylabel(\"\\% of training tasks\")\n",
    "axs[0].set_xlabel(\"\")\n",
    "axs[1].set_xlabel(\"Value of $b$\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../figures/ood_details.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}